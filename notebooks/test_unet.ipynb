{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f227f55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\pinokio\\bin\\miniconda\\lib\\site-packages (2.2.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Usando dispositivo: cuda\n",
      "\n",
      "--- ¡Comenzando el Entrenamiento! ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\sergi\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\sergi\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\sergi\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\sergi\\appdata\\roaming\\python\\python310\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.0563\n",
      "Epoch [2/20], Loss: 0.0127\n",
      "Epoch [3/20], Loss: 0.0063\n",
      "Epoch [4/20], Loss: 0.0040\n",
      "Epoch [5/20], Loss: 0.0032\n",
      "Epoch [6/20], Loss: 0.0028\n",
      "Epoch [7/20], Loss: 0.0025\n",
      "Epoch [8/20], Loss: 0.0022\n",
      "Epoch [9/20], Loss: 0.0021\n",
      "Epoch [10/20], Loss: 0.0019\n",
      "Epoch [11/20], Loss: 0.0018\n",
      "Epoch [12/20], Loss: 0.0018\n",
      "Epoch [13/20], Loss: 0.0017\n",
      "Epoch [14/20], Loss: 0.0016\n",
      "Epoch [15/20], Loss: 0.0015\n",
      "Epoch [16/20], Loss: 0.0013\n",
      "Epoch [17/20], Loss: 0.0011\n",
      "Epoch [18/20], Loss: 0.0010\n",
      "Epoch [19/20], Loss: 0.0008\n",
      "Epoch [20/20], Loss: 0.0008\n",
      "--- ¡Entrenamiento Finalizado! ---\n",
      "Modelo guardado en '../outputs/simple_unet_colorizer.pth'\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# --- 0. Parámetros de Configuración ---\n",
    "NUM_EPOCHS = 30\n",
    "LEARNING_RATE = 1e-3\n",
    "BATCH_SIZE = 8\n",
    "DUMMY_DATA_COUNT = 40\n",
    "\n",
    "# --- 1. Definición del Modelo U-Net Simple ---\n",
    "class SimpleUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleUNet, self).__init__()\n",
    "\n",
    "        # Encoder (Camino de bajada)\n",
    "        self.enc_conv1 = self.conv_block(1, 64) # Grayscale in, 64 out\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.enc_conv2 = self.conv_block(64, 128)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = self.conv_block(128, 256)\n",
    "\n",
    "        # Decoder (Camino de subida)\n",
    "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec_conv2 = self.conv_block(256, 128) # 128 (from upconv) + 128 (from skip)\n",
    "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec_conv1 = self.conv_block(128, 64) # 64 (from upconv) + 64 (from skip)\n",
    "        \n",
    "        # Capa Final\n",
    "        self.out_conv = nn.Conv2d(64, 3, kernel_size=1) # 64 in, 3 out (RGB)\n",
    "        self.final_activation = nn.Sigmoid() # Para que los píxeles estén entre 0 y 1\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e1 = self.enc_conv1(x)\n",
    "        p1 = self.pool1(e1)\n",
    "        e2 = self.enc_conv2(p1)\n",
    "        p2 = self.pool2(e2)\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(p2)\n",
    "\n",
    "        # Decoder con Skip Connections\n",
    "        d2 = self.upconv2(b)\n",
    "        d2 = torch.cat([d2, e2], dim=1) # Skip connection\n",
    "        d2 = self.dec_conv2(d2)\n",
    "\n",
    "        d1 = self.upconv1(d2)\n",
    "        d1 = torch.cat([d1, e1], dim=1) # Skip connection\n",
    "        d1 = self.dec_conv1(d1)\n",
    "\n",
    "        # Salida\n",
    "        output = self.out_conv(d1)\n",
    "        output = self.final_activation(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# --- 2. Generador de Datos (Dataset) ---\n",
    "class ColorizationDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.image_files = [f for f in os.listdir(root_dir) if f.endswith('.png')]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.image_files[idx])\n",
    "        color_image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        if self.transform:\n",
    "            color_image = self.transform(color_image)\n",
    "        \n",
    "        # Crear la entrada en escala de grises\n",
    "        grayscale_image = transforms.Grayscale()(color_image)\n",
    "        \n",
    "        return grayscale_image, color_image\n",
    "\n",
    "\n",
    "# --- 3. Bucle Principal de Entrenamiento ---\n",
    "if __name__ == '__main__':\n",
    "    # Setup\n",
    "    torch.cuda.empty_cache() # Limpiar caché de CUDA\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Usando dispositivo: {device}\")\n",
    "    \n",
    "    # Preparar Dataset y DataLoader\n",
    "    transform = transforms.Compose([transforms.Resize((128, 128)), transforms.ToTensor()])\n",
    "    dataset = ColorizationDataset(root_dir='../data/colors', transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    \n",
    "    # Instanciar modelo, pérdida y optimizador\n",
    "    model = SimpleUNet().to(device)\n",
    "    criterion = nn.MSELoss() # Mean Squared Error es buena para comparar imágenes\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    print(\"\\n--- ¡Comenzando el Entrenamiento! ---\")\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        running_loss = 0.0\n",
    "        for gray_imgs, color_imgs in dataloader:\n",
    "            gray_imgs = gray_imgs.to(device)\n",
    "            color_imgs = color_imgs.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(gray_imgs)\n",
    "            loss = criterion(outputs, color_imgs)\n",
    "            \n",
    "            # Backward pass y optimización\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], Loss: {running_loss/len(dataloader):.4f}\")\n",
    "        \n",
    "    print(\"--- ¡Entrenamiento Finalizado! ---\")\n",
    "\n",
    "    # Guardar el modelo entrenado\n",
    "    torch.save(model.state_dict(), '../outputs/simple_unet_colorizer.pth')\n",
    "    print(\"Modelo guardado en '../outputs/simple_unet_colorizer.pth'\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1564c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagen inferida guardada en: ../outputs/inference_result.png\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Inferencia en una imagen específica ---\n",
    "def inference(model_path, image_path, output_path):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Cargar modelo\n",
    "    model = SimpleUNet().to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    # Transform idéntico al entrenamiento\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    # Abrir imagen, convertir a RGB y luego a grayscale\n",
    "    color_image = Image.open(image_path).convert(\"RGB\")\n",
    "    gray_image = transforms.Grayscale()(color_image)\n",
    "    gray_tensor = preprocess(gray_image).unsqueeze(0).to(device)  # añadir batch\n",
    "\n",
    "    # Inferencia\n",
    "    with torch.no_grad():\n",
    "        output = model(gray_tensor)\n",
    "\n",
    "    # Convertir a imagen y guardar\n",
    "    output_image = transforms.ToPILImage()(output.squeeze(0).cpu())\n",
    "    output_image.save(output_path)\n",
    "    print(f\"Imagen inferida guardada en: {output_path}\")\n",
    "\n",
    "\n",
    "# Ejemplo de uso\n",
    "inference(\n",
    "    model_path='../outputs/simple_unet_colorizer.pth',\n",
    "    image_path=r'C:\\Users\\sergi\\Pictures\\vlcsnap-2025-02-17-17h59m59s967.png',\n",
    "    output_path='../outputs/inference_result.png'\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
