# Framework de Traducci√≥n Imagen-a-Imagen

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)
![TensorBoard](https://img.shields.io/badge/TensorBoard-Logging-orange.svg)

**DeepCopycat** es un framework flexible y modular construido en PyTorch para tareas de traducci√≥n de imagen a imagen. El proyecto utiliza una arquitectura U-Net que puede ser potenciada por diferentes "columnas vertebrales" (encoders), permitiendo una experimentaci√≥n r√°pida y la adaptaci√≥n a diversos problemas visuales como la generaci√≥n de m√°scaras (mattes), segmentaci√≥n, o colorizaci√≥n.

## ‚ú® Caracter√≠sticas Principales

* **Arquitectura U-Net Modular:** Un dise√±o limpio que separa el encoder del decoder.
* **Encoders Intercambiables:** Soporta tanto un **encoder convolucional cl√°sico** (eficiente y robusto) como un **encoder Vision Transformer (DINOv2)** pre-entrenado para un entendimiento sem√°ntico de vanguardia.
* **Monitoreo en Vivo con TensorBoard:** Visualiza las curvas de p√©rdida de entrenamiento y validaci√≥n en tiempo real a trav√©s de una interfaz web.
* **Inferencia de Alta Resoluci√≥n:** Incluye un script de inferencia con una t√©cnica de "ventana deslizante con solapamiento" para procesar im√°genes de cualquier tama√±o (HD, 4K) sin artefactos ni costuras.
* **Entrenamiento Flexible:** Configuraci√≥n completa a trav√©s de argumentos de l√≠nea de comandos, incluyendo la capacidad de reanudar el entrenamiento desde un checkpoint guardado.
* **Carga de Datos Robusta:** El `Dataset` personalizado maneja de forma segura el emparejamiento de archivos con nombres inconsistentes y aplica aumentaci√≥n de datos de forma sincronizada.

## üìÇ Estructura del Proyecto
u_proyecto/
‚îú‚îÄ‚îÄ data/              # Directorio para los datasets (no trackeado por Git)
‚îÇ   ‚îî‚îÄ‚îÄ mate/
‚îÇ       ‚îú‚îÄ‚îÄ rgb/
‚îÇ       ‚îî‚îÄ‚îÄ mask/
‚îú‚îÄ‚îÄ models/            # Modelos entrenados (.pth) (no trackeado por Git)
‚îú‚îÄ‚îÄ runs/              # Logs de TensorBoard (no trackeado por Git)
‚îî‚îÄ‚îÄ src/               # C√≥digo fuente principal
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îî‚îÄ‚îÄ logger.py  # M√≥dulo de logging para TensorBoard
‚îú‚îÄ‚îÄ dataset.py     # Clases de Dataset (RedChannelDataset, etc.)
‚îú‚îÄ‚îÄ model.py       # Arquitectura modular CopycatUNet
‚îú‚îÄ‚îÄ train.py       # Script de entrenamiento principal
‚îî‚îÄ‚îÄ inference.py   # Script de inferencia para im√°genes de alta resoluci√≥n


## ‚öôÔ∏è Configuraci√≥n del Entorno

1.  **Clona el repositorio:**
    ```bash
    git clone <URL-DEL-REPOSITORIO>
    cd tu_proyecto
    ```
2.  **Crea el entorno de Conda:** (Si tienes un `conda.yaml`)
    ```bash
    conda env create -f conda.yaml
    conda activate dinov2
    ```
3.  **Instala las dependencias necesarias:**
    ```bash
    pip install torch torchvision numpy opencv-python tqdm pillow tensorboard
    ```

## üöÄ Gu√≠a de Uso

Todos los comandos se ejecutan desde la carpeta `src/`.

### 1. Preparar el Dataset

Aseg√∫rate de que tus datos sigan la estructura esperada dentro de la carpeta `data/`. Por ejemplo, para la tarea de generaci√≥n de mattes:
* Im√°genes de entrada en `../data/mate/rgb/`
* M√°scaras objetivo en `../data/mate/mask/`

### 2. Entrenamiento

El script `train.py` es altamente configurable.

**Comando de Entrenamiento B√°sico (con encoder cl√°sico):**
Este comando inicia un entrenamiento de 150 √©pocas con la UNet cl√°sica, usando la p√©rdida BCE recomendada para m√°scaras.

```bash
python train.py --encoder classic --loss_fn bce --num_epochs 150 --batch_size 8
```
Entrenamiento con el Encoder DINOv2:
Aqu√≠ usamos el encoder DINOv2. Nota que --crop_size debe ser un m√∫ltiplo de 14 (el tama√±o de parche de DINOv2).


```bash

python train.py --encoder dinov2 --loss_fn bce --num_epochs 100 --crop_size 392 --batch_size 4
```
Reanudar un Entrenamiento Interrumpido:
Si un entrenamiento se detuvo, puedes continuarlo desde el √∫ltimo checkpoint guardado usando el flag --resume_from. El script cargar√° el modelo, el optimizador y continuar√° desde la √©poca correcta.

```bash
# Supongamos que el entrenamiento anterior lleg√≥ a 100 √©pocas y quieres continuar hasta 250
python train.py --encoder classic --num_epochs 250 --resume_from ../models/best_model_classic.pth
```

### 3. Monitoreo con TensorBoard
Mientras tu modelo entrena, puedes visualizar las gr√°ficas de p√©rdida en vivo.

Inicia el entrenamiento en una terminal como se describi√≥ arriba.

Abre una SEGUNDA terminal.

Navega a la ra√≠z de tu proyecto (la carpeta que contiene src/, runs/, etc.).

Ejecuta el servidor de TensorBoard:

```bash
tensorboard --logdir runs
```
Abre tu navegador web y ve a la direcci√≥n que te indica la terminal (usualmente http://localhost:6006/). Ver√°s tus gr√°ficas actualiz√°ndose despu√©s de cada √©poca.

### 4. Inferencia
Una vez que tengas un modelo entrenado (.pth), usa inference.py para procesar im√°genes nuevas en alta resoluci√≥n.

Inferencia con un Modelo "Cl√°sico":
Usa el archivo .pth generado con el encoder classic y especifica --encoder classic.

```bash
python inference.py \
    --model_path "../models/best_model_classic.pth" \
    --input "../data/imagenes_para_probar/foto_01.png" \
    --output "../outputs/foto_01_matte.png" \
    --encoder classic \
    --n_out_channels 1 \
    --window_size 1024
```

Inferencia con un Modelo "DINOv2":
Apunta al modelo entrenado con dinov2 y especifica --encoder dinov2. El script ajustar√° autom√°ticamente el --window_size si no es un m√∫ltiplo de 14.

```bash
python inference.py \
    --model_path "../models/best_model_dinov2.pth" \
    --input "../data/imagenes_para_probar/foto_02.png" \
    --output "../outputs/foto_02_matte.png" \
    --encoder dinov2 \
    --n_out_channels 1 \
    --window_s
```

